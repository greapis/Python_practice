{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNBIJPwN7QILBl46vssEjjI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/greapis/Python_practice/blob/main/Tensorflow_AI_LS_CIFAR_10(CNN).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CIFAR-10 Datasets은 제공됨\n",
        " - MNIST : from tensorflow.keras.datasets import mnist\n",
        " - CIFAR-10 Datasets 역시 keras에서 기본적으로 제공"
      ],
      "metadata": {
        "id": "WCWev_JrZUrW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Road library\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "  #  keras에서 Datasets 제공\n",
        "\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "  # using \"One-Hot Encoding\"\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "r-kFHl77Zrb1"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data 전처리\n",
        " - X : 정규화(MNIST와 동일)\n",
        "\n",
        "     각 픽셀은 0과 255 사이의 정수값으로 설정됨\n",
        "     해당 값들을 0과 1로 정규화하는 것이 필요\n",
        "\n",
        " - Y : Label Encoding : One-Hot Encoding\n",
        "     각 클래스를 독립적인 카테고리로 인식하기 위함\n",
        "         airplaine  = [1,0,0,0,0,0,0,0,0,0]\n",
        "         automobile = [0,1,0,0,0,0,0,0,0,0]   "
      ],
      "metadata": {
        "id": "YaV8QbLnmhiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data 전처리\n",
        "\n",
        "# Roding CIFAR-10 datasets\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "  # x : pixels value(0~255),\n",
        "  # y : labels (airplane, bird 등)\n",
        "\n",
        "# Ont-Hot Encoding 적용\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "# Nomalization data\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "metadata": {
        "id": "k5AiGK7yni-W"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 구축 : 1번 합성곱 + 풀링 layer\n",
        "\n",
        " - 합성곱 layer(Convolutional Layer)\n",
        "\n",
        "   필터수, 커널 크기(커널 = filter), 활성화 함수 설정\n",
        "\n",
        "   input_shape = (32,32,3)인 이유는 RGB가 포함되었기 때문\n",
        "   \n",
        "\n",
        " - Pooling Layer : Max Pooling\n",
        "\n",
        "   Pooling filter size : (2 X 2)\n",
        "\n",
        "   Max Pooling : (2 X 2) 블록 내에서 가장 큰 값을 선정\n"
      ],
      "metadata": {
        "id": "CuepKDVztREd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN Model_1 : Convolutional + Pooling Layers\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32,32,3)))\n",
        "  #  Conv2D(32, (3, 3))) 32:필터 수, (3, 3) : 커널 크기\n",
        "\n",
        "model.add(layers.MaxPooling2D(2,2))\n",
        "  #  MaxPooling2D(2,2) : Pooling filer 크기 : (2,2)\n",
        "\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D(2,2))\n",
        "  #  Convolutional layer, MaxPooling layer를 2번 반복\n",
        "    #  모델 성능을높이고 싶다면 'Convolutional layer, MaxPooling layer' 부분 추가 가능\n"
      ],
      "metadata": {
        "id": "b2lxvx6uq9bW",
        "outputId": "bec95e01-33dc-4b5d-b34f-e6b421d74e6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "스트라이드와 패딩 (stride // padding)\n",
        "\n",
        "\n",
        "  - Stride\n",
        "\n",
        "Stride는 필터가 입력 데이터를 얼마나 이동하는지를 나타냅니다. 예를 들어, stride가 1이면 필터는 한 번에 한 칸씩 이동하고, stride가 2이면 두 칸씩 이동합니다. Stride가 크면 입력 데이터의 크기가 더 많이 줄어듭니다.\n",
        "\n",
        "stride가 크면, filter의 이동이 크고 feature map이 적고\n",
        "stride가 작으면, filter의 이동이 작고 feature map이 크고\n",
        "\n",
        "\n",
        "\n",
        "  - Padding\n",
        "\n",
        "Padding은 입력 데이터의 테두리에 추가적인 픽셀을 추가하는 것을 말합니다. 패딩은 일반적으로 두 가지 이유로 사용됩니다:\n",
        "\n",
        "출력 크기 조정: 패딩을 사용하지 않으면 합성곱 연산 후 출력 데이터의 크기가 줄어들 수 있습니다. 패딩을 사용하면 원래 입력 데이터와 동일한 크기의 출력을 유지할 수 있습니다.\n",
        "\n",
        "경계 정보 보존: 입력 데이터의 경계 부분을 보존하고 싶을 때 패딩을 사용합니다."
      ],
      "metadata": {
        "id": "7QsQrZiplUK9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of stride and padding\n",
        "\n",
        "# - Stride\n",
        "#    strides = 1\n",
        "#    strides = 2\n",
        "\n",
        "# - Padding\n",
        "#    padding = 'valid' : padding 추가 X\n",
        "#    padding = 'same'  : padding 추가 : 입력크기 = 출력크기 (동일)"
      ],
      "metadata": {
        "id": "NKAYe1WFl3i0"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Revising CNN Code (조정 of stride and padding)\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), strides=1, padding ='same', activation='relu', input_shape=(32, 32, 3)))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=2))\n",
        "\n",
        "model.add(layers.Conv2D(64, (3, 3), strides=1, padding='same', activation='relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=1))\n"
      ],
      "metadata": {
        "id": "dE5ii-wwnRVq"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 구축 : 2번 Fully Connected Layer (완전 연결 layers)\n",
        "\n",
        "\n",
        " - Fully Connected Layer는 CNN의 마지막 부분에 위치\n",
        "\n",
        "   이전 층에서 추출된 특징들을 바탕으로 최종 예측을 수행합니다.\n",
        "\n",
        "\n",
        " - Flatten\n",
        "\n",
        "   완전 연결 레이어에 데이터 1D로 변환\n",
        "   \n",
        "\n",
        " - Softmax\n",
        "\n",
        "   다중 클래스 분류 문제에서 각 클래스 확률을 출력하기 위함\n",
        "\n",
        "   각 클래스 확률 합 = '1'\n",
        "\n",
        "\n",
        " - 완전 연결 레이어의 역할\n",
        "\n",
        "    특징 결합: 이전 합성곱 층과 풀링 층에서 추출된 특징들을 결합\n",
        "\n",
        "    예측 수행: 각 클래스에 대한 확률을 계산하여 최종 분류를 수행\n",
        "\n",
        " - 작동 원리\n",
        "  \n",
        "    입력: 이전 층에서 추출된 특징 맵(feature map)이 1차원 벡터로 변환, 이를 벡터화(flattening)라고 함\n",
        "\n",
        "    가중치와 곱셈: 입력 벡터와 가중치(weight)가 곱해지고, 편향(bias)이 추가\n",
        "\n",
        "    활성화 함수: ReLU(Rectified Linear Unit) 또는 소프트맥스(Softmax) 적용"
      ],
      "metadata": {
        "id": "ReA1ZtRq7tHz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN Model_2 : Fully Connected Layers(FC)\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "    # Dense(64, )  64는 nodes의 수\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "    # Dense(10, )  10는 nodes의 수, 10개의 nodes로 한 이유는 'CIFAR-10'의 Class가 10개 이기 때문에\n",
        "\n",
        "    # 'Softmax' activation은 각 클래스에 대한 확률을 합이 '1'이 됨\n",
        "    #  ex) 첫 번째 'airplane'의 확률 = [0.982, 0.001, 0.0003, 0.00005, 0.00005, 0.000005, 0.0054, 0.0000005, 0.0000746, 0.011115]"
      ],
      "metadata": {
        "id": "_ksdIpNIn0py"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Compile"
      ],
      "metadata": {
        "id": "izO4eIGKkXjX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Compile\n",
        "\n",
        "#  환경 설정\n",
        "#   Optimizer : Adam\n",
        "#   Loss : Categorical Crossentropy\n",
        "#   Metrics : Accuracy\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "LYsOTq3NzVmb"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 학습\n",
        "\n",
        " - 일련의 설정 기반으로 모델 학습\n",
        "\n",
        "   model.fit() : 구성된 모델로 학습해라\n",
        "\n",
        "   학습 DATA : (Image) x_train,  (Labels) y_train\n",
        "\n",
        "   Hyper Parameter : epoch, batch_size\n",
        "\n",
        "   Ratio of Learning/Test\n",
        "\n",
        "\n",
        " - Designating Hyper Parameter\n",
        "\n",
        "   epoch : 10 / batch_size : 32\n",
        "\n",
        " - Setting Ratio of Learning/Test\n",
        "\n",
        "   Validation_split : 검증 데이터 비율 = 20%\n",
        "\n",
        "   학습 데이터 수 = 50,000 * 0.8 = 40,000"
      ],
      "metadata": {
        "id": "ScxQMz7B0dVj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Code : Learning Model\n",
        "\n",
        "model.fit(x_train, y_train, epochs=10, batch_size=32, validation_split=0.2)"
      ],
      "metadata": {
        "id": "RdSFCvbizsyx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3c4c73b-9ebc-43d8-dd62-ed18cdc23f65"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 80ms/step - accuracy: 0.3382 - loss: 1.7898 - val_accuracy: 0.5833 - val_loss: 1.1916\n",
            "Epoch 2/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 80ms/step - accuracy: 0.6074 - loss: 1.1098 - val_accuracy: 0.6540 - val_loss: 0.9922\n",
            "Epoch 3/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 80ms/step - accuracy: 0.6656 - loss: 0.9406 - val_accuracy: 0.6728 - val_loss: 0.9493\n",
            "Epoch 4/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 78ms/step - accuracy: 0.7083 - loss: 0.8327 - val_accuracy: 0.6811 - val_loss: 0.9256\n",
            "Epoch 5/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 76ms/step - accuracy: 0.7455 - loss: 0.7349 - val_accuracy: 0.6920 - val_loss: 0.9026\n",
            "Epoch 6/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 78ms/step - accuracy: 0.7710 - loss: 0.6589 - val_accuracy: 0.6961 - val_loss: 0.9106\n",
            "Epoch 7/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 76ms/step - accuracy: 0.7892 - loss: 0.5990 - val_accuracy: 0.6929 - val_loss: 0.9462\n",
            "Epoch 8/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 78ms/step - accuracy: 0.8127 - loss: 0.5358 - val_accuracy: 0.7009 - val_loss: 0.9242\n",
            "Epoch 9/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 77ms/step - accuracy: 0.8333 - loss: 0.4763 - val_accuracy: 0.7044 - val_loss: 0.9492\n",
            "Epoch 10/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 78ms/step - accuracy: 0.8471 - loss: 0.4373 - val_accuracy: 0.6868 - val_loss: 1.0604\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7ea4f7b757d0>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 성능 평가\n",
        "\n",
        " - 모델 성능지표 계산\n",
        "\n",
        "\n",
        "\n",
        " - evaluate는 반환 순서 고정됨\n",
        "\n",
        "\n",
        "\n",
        " - f\"문자열 {변수/표현식}\""
      ],
      "metadata": {
        "id": "ZSnLa1412UMd"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n6qESfRk14mp"
      },
      "execution_count": 21,
      "outputs": []
    }
  ]
}