{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPrYaNPBb+/p5NWivPDOXmr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/greapis/Python_practice/blob/main/Tensorflow_AI_LS_CIFAR_10(CNN).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CIFAR-10 Datasets은 제공됨\n",
        " - MNIST : from tensorflow.keras.datasets import mnist\n",
        " - CIFAR-10 Datasets 역시 keras에서 기본적으로 제공"
      ],
      "metadata": {
        "id": "WCWev_JrZUrW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Road library\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "  #  keras에서 Datasets 제공\n",
        "\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "  # using \"One-Hot Encoding\"\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "r-kFHl77Zrb1"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data 전처리\n",
        " - X : 정규화(MNIST와 동일)\n",
        "\n",
        "     각 픽셀은 0과 255 사이의 정수값으로 설정됨\n",
        "     해당 값들을 0과 1로 정규화하는 것이 필요\n",
        "\n",
        " - Y : Label Encoding : One-Hot Encoding\n",
        "     각 클래스를 독립적인 카테고리로 인식하기 위함\n",
        "         airplaine  = [1,0,0,0,0,0,0,0,0,0]\n",
        "         automobile = [0,1,0,0,0,0,0,0,0,0]   "
      ],
      "metadata": {
        "id": "YaV8QbLnmhiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data 전처리\n",
        "\n",
        "# Roding CIFAR-10 datasets\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "  # x : pixels value(0~255),\n",
        "  # y : labels (airplane, bird 등)\n",
        "\n",
        "# Ont-Hot Encoding 적용\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "# Nomalization data\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "metadata": {
        "id": "k5AiGK7yni-W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "066504e9-abd8-4a93-901a-88ee77626e7e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 구축 : 1번 합성곱 + 풀링 layer\n",
        "\n",
        " - 합성곱 layer(Convolutional Layer)\n",
        "\n",
        "   필터수, 커널 크기(커널 = filter), 활성화 함수 설정\n",
        "\n",
        "   input_shape = (32,32,3)인 이유는 RGB가 포함되었기 때문\n",
        "   \n",
        "\n",
        " - Pooling Layer : Max Pooling\n",
        "\n",
        "   Pooling filter size : (2 X 2)\n",
        "\n",
        "   Max Pooling : (2 X 2) 블록 내에서 가장 큰 값을 선정\n"
      ],
      "metadata": {
        "id": "CuepKDVztREd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN Model_1 : Convolutional + Pooling Layers\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32,32,3)))\n",
        "  #  Conv2D(32, (3, 3))) 32:필터 수, (3, 3) : 커널 크기\n",
        "\n",
        "model.add(layers.MaxPooling2D(2,2))\n",
        "  #  MaxPooling2D(2,2) : Pooling filer 크기 : (2,2)\n",
        "\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D(2,2))\n",
        "  #  Convolutional layer, MaxPooling layer를 2번 반복\n",
        "    #  모델 성능을높이고 싶다면 'Convolutional layer, MaxPooling layer' 부분 추가 가능\n"
      ],
      "metadata": {
        "id": "b2lxvx6uq9bW",
        "outputId": "4ac2b1a3-5865-48f4-be4d-8ff04f2922a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "스트라이드와 패딩 (stride // padding)\n",
        "\n",
        "\n",
        "  - Stride\n",
        "\n",
        "Stride는 필터가 입력 데이터를 얼마나 이동하는지를 나타냅니다. 예를 들어, stride가 1이면 필터는 한 번에 한 칸씩 이동하고, stride가 2이면 두 칸씩 이동합니다. Stride가 크면 입력 데이터의 크기가 더 많이 줄어듭니다.\n",
        "\n",
        "stride가 크면, filter의 이동이 크고 feature map이 적고\n",
        "stride가 작으면, filter의 이동이 작고 feature map이 크고\n",
        "\n",
        "\n",
        "\n",
        "  - Padding\n",
        "\n",
        "Padding은 입력 데이터의 테두리에 추가적인 픽셀을 추가하는 것을 말합니다. 패딩은 일반적으로 두 가지 이유로 사용됩니다:\n",
        "\n",
        "출력 크기 조정: 패딩을 사용하지 않으면 합성곱 연산 후 출력 데이터의 크기가 줄어들 수 있습니다. 패딩을 사용하면 원래 입력 데이터와 동일한 크기의 출력을 유지할 수 있습니다.\n",
        "\n",
        "경계 정보 보존: 입력 데이터의 경계 부분을 보존하고 싶을 때 패딩을 사용합니다."
      ],
      "metadata": {
        "id": "7QsQrZiplUK9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of stride and padding\n",
        "\n",
        "# - Stride\n",
        "#    strides = 1\n",
        "#    strides = 2\n",
        "\n",
        "# - Padding\n",
        "#    padding = 'valid' : padding 추가 X\n",
        "#    padding = 'same'  : padding 추가 : 입력크기 = 출력크기 (동일)"
      ],
      "metadata": {
        "id": "NKAYe1WFl3i0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Revising CNN Code (조정 of stride and padding)\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), strides=1, padding ='same', activation='relu', input_shape=(32, 32, 3)))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=2))\n",
        "\n",
        "model.add(layers.Conv2D(64, (3, 3), strides=1, padding='same', activation='relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=1))\n"
      ],
      "metadata": {
        "id": "dE5ii-wwnRVq"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 구축 : 2번 Fully Connected Layer (완전 연결 layers)\n",
        "\n",
        "\n",
        " - Fully Connected Layer는 CNN의 마지막 부분에 위치\n",
        "\n",
        "   이전 층에서 추출된 특징들을 바탕으로 최종 예측을 수행합니다.\n",
        "\n",
        "\n",
        " - Flatten\n",
        "\n",
        "   완전 연결 레이어에 데이터 1D로 변환\n",
        "   \n",
        "\n",
        " - Softmax\n",
        "\n",
        "   다중 클래스 분류 문제에서 각 클래스 확률을 출력하기 위함\n",
        "\n",
        "   각 클래스 확률 합 = '1'\n",
        "\n",
        "\n",
        " - 완전 연결 레이어의 역할\n",
        "\n",
        "    특징 결합: 이전 합성곱 층과 풀링 층에서 추출된 특징들을 결합\n",
        "\n",
        "    예측 수행: 각 클래스에 대한 확률을 계산하여 최종 분류를 수행\n",
        "\n",
        " - 작동 원리\n",
        "  \n",
        "    입력: 이전 층에서 추출된 특징 맵(feature map)이 1차원 벡터로 변환, 이를 벡터화(flattening)라고 함\n",
        "\n",
        "    가중치와 곱셈: 입력 벡터와 가중치(weight)가 곱해지고, 편향(bias)이 추가\n",
        "\n",
        "    활성화 함수: ReLU(Rectified Linear Unit) 또는 소프트맥스(Softmax) 적용"
      ],
      "metadata": {
        "id": "ReA1ZtRq7tHz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN Model_2 : Fully Connected Layers(FC)\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "    # Dense(64, )  64는 nodes의 수\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "    # Dense(10, )  10는 nodes의 수, 10개의 nodes로 한 이유는 'CIFAR-10'의 Class가 10개 이기 때문에\n",
        "\n",
        "    # 'Softmax' activation은 각 클래스에 대한 확률을 합이 '1'이 됨\n",
        "    #  ex) 첫 번째 'airplane'의 확률 = [0.982, 0.001, 0.0003, 0.00005, 0.00005, 0.000005, 0.0054, 0.0000005, 0.0000746, 0.011115]"
      ],
      "metadata": {
        "id": "_ksdIpNIn0py"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Compile"
      ],
      "metadata": {
        "id": "izO4eIGKkXjX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Compile\n",
        "\n",
        "#  환경 설정\n",
        "#   Optimizer : Adam\n",
        "#   Loss : Categorical Crossentropy\n",
        "#   Metrics : Accuracy\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  #  categorical_crossentropy : 주로 multi class classification에서 사용"
      ],
      "metadata": {
        "id": "LYsOTq3NzVmb"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 학습\n",
        "\n",
        " - 일련의 설정 기반으로 모델 학습\n",
        "\n",
        "   model.fit() : 구성된 모델로 학습해라\n",
        "\n",
        "   학습 DATA : (Image) x_train,  (Labels) y_train\n",
        "\n",
        "   Hyper Parameter : epoch, batch_size\n",
        "\n",
        "   Ratio of Learning/Test\n",
        "\n",
        "\n",
        " - Designating Hyper Parameter\n",
        "\n",
        "   epoch : 10 / batch_size : 32\n",
        "\n",
        " - Setting Ratio of Learning/Test\n",
        "\n",
        "   Validation_split : 검증 데이터 비율 = 20%\n",
        "\n",
        "   학습 데이터 수 = 50,000 * 0.8 = 40,000"
      ],
      "metadata": {
        "id": "ScxQMz7B0dVj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Code : Learning Model\n",
        "\n",
        "model.fit(x_train, y_train, epochs=10, batch_size=32, validation_split=0.2)"
      ],
      "metadata": {
        "id": "RdSFCvbizsyx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "851206cd-0391-4bbf-8143-6dce5901b2dc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 69ms/step - accuracy: 0.5467 - loss: 1.2830 - val_accuracy: 0.6424 - val_loss: 1.0330\n",
            "Epoch 2/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 69ms/step - accuracy: 0.6613 - loss: 0.9847 - val_accuracy: 0.6686 - val_loss: 0.9547\n",
            "Epoch 3/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 72ms/step - accuracy: 0.7149 - loss: 0.8220 - val_accuracy: 0.6874 - val_loss: 0.9160\n",
            "Epoch 4/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 69ms/step - accuracy: 0.7506 - loss: 0.7094 - val_accuracy: 0.6820 - val_loss: 0.9384\n",
            "Epoch 5/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 67ms/step - accuracy: 0.7828 - loss: 0.6253 - val_accuracy: 0.6940 - val_loss: 0.9445\n",
            "Epoch 6/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 70ms/step - accuracy: 0.8117 - loss: 0.5480 - val_accuracy: 0.7079 - val_loss: 0.9214\n",
            "Epoch 7/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 66ms/step - accuracy: 0.8337 - loss: 0.4747 - val_accuracy: 0.6973 - val_loss: 0.9711\n",
            "Epoch 8/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 66ms/step - accuracy: 0.8602 - loss: 0.4070 - val_accuracy: 0.7023 - val_loss: 1.0246\n",
            "Epoch 9/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 73ms/step - accuracy: 0.8800 - loss: 0.3438 - val_accuracy: 0.6911 - val_loss: 1.1318\n",
            "Epoch 10/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 71ms/step - accuracy: 0.8988 - loss: 0.2904 - val_accuracy: 0.6902 - val_loss: 1.2148\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x797c243ea6d0>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 성능 평가\n",
        "\n",
        " - 모델 성능지표 계산\n",
        "\n",
        "   model.evaluate : 학습된 모델을 평가, 손실값과 정확도 등 반환\n",
        "\n",
        "   test data : x_test = images // y_test = labels\n",
        "\n",
        "\n",
        " - evaluate는 반환 순서 고정됨\n",
        "   \n",
        "   evaluate의 반환 순서 : loss - metrics1 - metrics2 - metrics3 - .... 으로 고정\n",
        "\n",
        "   앞서 'model compile' 과정에서 (metrics = ['accuracy']로 설정함\n",
        "\n",
        "\n",
        " - f\"문자열 {변수/표현식}\"\n",
        "\n",
        "   f-string : 문자열 안에 변수나 표현식을 직접 삽입하는 방법 / 문자열 앞에 'f'를 붙임"
      ],
      "metadata": {
        "id": "ZSnLa1412UMd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 평가\n",
        "\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "  # test_loss : 손실값 = 오차의 크기\n",
        "  # test_acc  : 정확도 = 정답을 맞춘 비율\n",
        "\n",
        "test_loss = round(test_loss, 4)\n",
        "  # 손실값을 소수점 4자리까지 반올림 표시\n",
        "test_acc = round(test_acc, 4)\n",
        "  # 정확도를 소수점 4자리까지 반올림 표시\n",
        "\n",
        "\n",
        "\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "  # 'test_loss: .4f' : test_loss 값을 소수점 4자리로 출력"
      ],
      "metadata": {
        "id": "n6qESfRk14mp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b711f9e6-2455-4d57-a5ad-d54adc81347b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - accuracy: 0.6929 - loss: 1.1967\n"
          ]
        }
      ]
    }
  ]
}